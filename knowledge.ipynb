{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:09:42.663773Z",
     "start_time": "2018-06-09T03:09:42.440156Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import requests\n",
    "import urllib.request\n",
    "import re, string\n",
    "from collections import deque\n",
    "\n",
    "link_queue = deque()\n",
    "processed_links = {}\n",
    "edges = []\n",
    "base = \"https://en.wikipedia.org\"\n",
    "from_link = \"/wiki/Markov_model\"\n",
    "\n",
    "url = f\"{base}{from_link}\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:09:43.533011Z",
     "start_time": "2018-06-09T03:09:43.200199Z"
    }
   },
   "outputs": [],
   "source": [
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "html = urllib.request.urlopen(url).read()\n",
    "text = text_from_html(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:17:22.194957Z",
     "start_time": "2018-06-09T03:17:22.190920Z"
    }
   },
   "outputs": [],
   "source": [
    "text = text.lower()\n",
    "pattern = re.compile('[^a-z ]')\n",
    "pattern2 = re.compile(' +')\n",
    "text = pattern2.sub(\" \", pattern.sub(\"\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:19:06.312672Z",
     "start_time": "2018-06-09T03:19:06.310013Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-58-c3868ada2b2d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-58-c3868ada2b2d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    patternn.\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(\"\\W+ markov \\W+\")\n",
    "patternn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:21:58.541621Z",
     "start_time": "2018-06-09T03:21:58.538208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a markov model',\n",
       " 'the markov property',\n",
       " 'the markov property',\n",
       " 'introduction markov chain',\n",
       " 'hidden markov model',\n",
       " 'observable markov decision',\n",
       " 'process markov random',\n",
       " 'hierarchical markov models',\n",
       " 'tolerant markov model',\n",
       " 'common markov models',\n",
       " 'made markov models',\n",
       " 'autonomous markov chain',\n",
       " 'hidden markov model',\n",
       " 'controlled markov decision',\n",
       " 'observable markov decision',\n",
       " 'process markov chain',\n",
       " 'article markov chain',\n",
       " 'simplest markov model',\n",
       " 'the markov chain',\n",
       " 'the markov property',\n",
       " 'a markov chain',\n",
       " 'is markov chain',\n",
       " 'the markov property',\n",
       " 'hidden markov model',\n",
       " 'hidden markov model',\n",
       " 'hidden markov model',\n",
       " 'a markov chain',\n",
       " 'hidden markov models',\n",
       " 'hidden markov model',\n",
       " 'audio markov decision',\n",
       " 'article markov decision',\n",
       " 'a markov decision',\n",
       " 'a markov chain',\n",
       " 'a markov decision',\n",
       " 'observable markov decision',\n",
       " 'observable markov decision',\n",
       " 'a markov decision',\n",
       " 'robots markov random',\n",
       " 'a markov random',\n",
       " 'or markov network',\n",
       " 'a markov chain',\n",
       " 'a markov chain',\n",
       " 'a markov random',\n",
       " 'a markov random',\n",
       " 'a markov random',\n",
       " 'hierarchical markov models',\n",
       " 'hierarchical markov models',\n",
       " 'hierarchical markov models',\n",
       " 'hidden markov model',\n",
       " 'hidden markov model',\n",
       " 'tolerant markov model',\n",
       " 'tolerant markov model',\n",
       " 'probabilisticalgorithmic markov chain',\n",
       " 'edit markov chain',\n",
       " 'carlo markov blanket',\n",
       " 'andrey markov variableorder',\n",
       " 'a markov chains',\n",
       " 'hidden markov model',\n",
       " 'hidden markov model',\n",
       " 'observable markov decision',\n",
       " 'tolerant markov models',\n",
       " 'categories markov models']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\w+ markov \\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:20:42.645179Z",
     "start_time": "2018-06-09T03:20:42.642498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' markov model from wikipedia the free encyclopedia jump to navigation search this article needs additional citations for verification please help improve this article by adding citations to reliable sources unsourced material may be challenged and removed july learn how and when to remove this template message in probability theory a markov model is a stochastic model used to model randomly changing systems it is assumed that future states depend only on the current state not on the events that occurred before it that is it assumes the markov property generally this assumption enables reasoning and computation with the model that would otherwise be intractable for this reason in the fields of predictive modelling and probabilistic forecasting it is desirable for a given model to exhibit the markov property contents introduction markov chain hidden markov model markov decision process partially observable markov decision process markov random field hierarchical markov models tolerant markov model see also references introduction edit there are four common markov models used in different situations depending on whether every sequential state is observable or not and whether the system is to be adjusted on the basis of observations made markov models system state is fully observable system state is partially observable system is autonomous markov chain hidden markov model system is controlled markov decision process partially observable markov decision process markov chain edit main article markov chain the simplest markov model is the markov chain it models the state of a system with a random variable that changes through time in this context the markov property suggests that the distribution for this variable depends only on the distribution of previous state an example use of a markov chain is markov chain monte carlo which uses the markov property to prove that a particular method for performing a random walk will sample from the joint distribution hidden markov model edit main article hidden markov model a hidden markov model is a markov chain for which the state is only partially observable in other words observations are related to the state of the system but they are typically insufficient to precisely determine the state several wellknown algorithms for hidden markov models exist for example given a sequence of observations the viterbi algorithm will compute the mostlikely corresponding sequence of states the forward algorithm will compute the probability of the sequence of observations and the baumwelch algorithm will estimate the starting probabilities the transition function and the observation function of a hidden markov model one common use is for speech recognition where the observed data is the speech audio waveform and the hidden state is the spoken text in this example the viterbi algorithm finds the most likely sequence of spoken words given the speech audio markov decision process edit main article markov decision process a markov decision process is a markov chain in which state transitions depend on the current state and an action vector that is applied to the system typically a markov decision process is used to compute a policy of actions that will maximize some utility with respect to expected rewards it is closely related to reinforcement learning and can be solved with value iteration and related methods partially observable markov decision process edit a partially observable markov decision process pomdp is a markov decision process in which the state of the system is only partially observed pomdps are known to be np complete but recent approximation techniques have made them useful for a variety of applications such as controlling simple agents or robots markov random field edit a markov random field or markov network may be considered to be a generalization of a markov chain in multiple dimensions in a markov chain state depends only on the previous state in time whereas in a markov random field each state depends on its neighbors in any of multiple directions a markov random field may be visualized as a field or graph of random variables where the distribution of each random variable depends on the neighboring variables with which it is connected more specifically the joint distribution for any random variable in the graph can be computed as the product of the clique potentials of all the cliques in the graph that contain that random variable modeling a problem as a markov random field is useful because it implies that the joint distributions at each vertex in the graph may be computed in this manner hierarchical markov models edit hierarchical markov models can be applied to categorize human behavior at various levels of abstraction for example a series of simple observations such as a persons location in a room can be interpreted to determine more complex information such as in what task or activity the person is performing two kinds of hierarchical markov models are the hierarchical hidden markov model and the abstract hidden markov model both have been used for behavior recognition and certain conditional independence properties between different levels of abstraction in the model allow for faster learning and inference tolerant markov model edit a tolerant markov model tmm is a probabilisticalgorithmic markov chain model it assigns the probabilities according to a conditioning context that considers the last symbol from the sequence to occur as the most probable instead of the true occurring symbol a tmm can model three different natures substitutions additions or deletions successful applications have been efficiently implemented in dna sequences compression see also edit markov chain monte carlo markov blanket andrey markov variableorder markov model references edit a b gagniuc paul a markov chains from theory to implementation and experimentation usa nj john wiley sons pp isbn kaelbling l p littman m l cassandra a r planning and acting in partially observable stochastic domains abstract full article artificial intelligence elsevier doi sx issn retrieved march fine s singer y the hierarchical hidden markov model analysis and applications machine learning doi a a b bui h h venkatesh s west g policy recognition in the abstract hidden markov model journal of artificial intelligence research doi jair theocharous g hierarchical learning and planning in partially observable markov decision processes phd michigan state university luhr s bui h h venkatesh s west g a w recognition of human activity through hierarchical stochastic learning percom proceedings of the first ieee international conference on pervasive computing and communications doi percom a b pratas d hosseini m pinho a j substitutional tolerant markov models for relative compression of dna sequences pacbb th international conference on practical applications of computational biology bioinformatics porto portugal pp doi isbn pratas d pinho a j ferreira p j s g efficient compression of genomic sequences data compression conference dcc ieee pp doi dcc authority control gnd retrieved from httpsenwikipediaorgwindexphptitlemarkovmodeloldid categories markov models hidden categories articles needing additional references from july all articles needing additional references wikipedia articles with gnd identifiers navigation menu personal tools not logged in talk contributions create account log in namespaces article talk variants views read edit view history more search navigation main page contents featured content current events random article donate to wikipedia wikipedia store interaction help about wikipedia community portal recent changes contact page tools what links here related changes upload file special pages permanent link page information wikidata item cite this page printexport create a book download as pdf printable version in other projects wikimedia commons languages bahasa melayu edit links this page was last edited on may at text is available under the creative commons attributionsharealike license additional terms may apply by using this site you agree to the terms of use and privacy policy wikipedia is a registered trademark of the wikimedia foundation inc a nonprofit organization privacy policy about wikipedia disclaimers contact wikipedia developers cookie statement mobile view '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
