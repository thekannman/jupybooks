{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:24:38.103818Z",
     "start_time": "2018-06-09T23:24:38.083813Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:27:57.451920Z",
     "start_time": "2018-06-09T23:27:57.440951Z"
    }
   },
   "outputs": [],
   "source": [
    "#word = \"yooks\"\n",
    "#sample_text = [\n",
    "#\"yooks are not zooks.\",\n",
    "#\"yooks know how to cook.\",\n",
    "#\"yooks are from yooktown.\",\n",
    "#\"yooks are not from zooktown\",\n",
    "#\"yooks like to cook.\",\n",
    "#\"yooks like to read books.\",\n",
    "#\"yooks like to read magazines.\",\n",
    "#\"there are no yooks in zooktown.\"\n",
    "#]\n",
    "\n",
    "word = \"markov\"\n",
    "with open('matches.pkl', 'rb') as f:\n",
    "  sample_text = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:30:38.281236Z",
     "start_time": "2018-06-09T23:30:38.271207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'markov models used in different situations, depending on whether every sequential state is observable or not, and whether the system is to be adjusted on the basis of observations made:'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:27:59.513507Z",
     "start_time": "2018-06-09T23:27:59.508513Z"
    }
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:27:59.904516Z",
     "start_time": "2018-06-09T23:27:59.900507Z"
    }
   },
   "outputs": [],
   "source": [
    "iters = [pattern.finditer(text) for text in sample_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:28:01.008511Z",
     "start_time": "2018-06-09T23:28:00.998506Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_text = [word_tokenize(text) for text in  sample_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:36:28.849354Z",
     "start_time": "2018-06-09T23:36:28.841356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['markov',\n",
       " 'models',\n",
       " 'can',\n",
       " 'be',\n",
       " 'applied',\n",
       " 'to',\n",
       " 'categorize',\n",
       " 'human',\n",
       " 'behavior',\n",
       " 'at',\n",
       " 'various',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'abstraction']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:28:09.195001Z",
     "start_time": "2018-06-09T23:28:09.189997Z"
    }
   },
   "outputs": [],
   "source": [
    "word_indices = [text.index(word) for text in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:36:57.798880Z",
     "start_time": "2018-06-09T23:36:57.791883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:54:27.013066Z",
     "start_time": "2018-06-09T23:54:27.007069Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_tree = {\"name\": word}\n",
    "raw_tree[\"raw_children\"] = [text[i+1:] for i,text in zip(word_indices,tokenized_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:54:27.299067Z",
     "start_time": "2018-06-09T23:54:27.277069Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_child(child):\n",
    "  final = {\"name\": child[0]}\n",
    "  if len(child)==1:\n",
    "    final[\"size\"]=1\n",
    "  else:\n",
    "    final[\"children\"] = [process_child(child[1:])]\n",
    "  return final\n",
    "raw_tree[\"children\"] = [process_child(child) for child in raw_tree[\"raw_children\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:54:27.507064Z",
     "start_time": "2018-06-09T23:54:27.463069Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_children(children, depth=0):\n",
    "  new_children = {}\n",
    "  for child in children:\n",
    "    if child[\"name\"] in new_children:\n",
    "      new_children[child[\"name\"]].get(\"children\")\n",
    "      if child.get(\"children\") and new_children[child[\"name\"]].get(\"children\"):\n",
    "        new_children[child[\"name\"]][\"children\"] = combine_children(list(child[\"children\"])+ list(new_children[child[\"name\"]][\"children\"]), depth=depth+1)\n",
    "      elif child.get(\"children\"):\n",
    "        new_children[child[\"name\"]][\"children\"] = child[\"children\"]\n",
    "      new_children[child[\"name\"]][\"size\"] = new_children[child[\"name\"]].get(\"size\",0) + child.get(\"size\",0)\n",
    "    else:\n",
    "      new_children[child[\"name\"]] = child\n",
    "  return list(new_children.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:54:27.654066Z",
     "start_time": "2018-06-09T23:54:27.639070Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_tree[\"children\"] = combine_children(raw_tree[\"children\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:54:27.904068Z",
     "start_time": "2018-06-09T23:54:27.885065Z"
    }
   },
   "outputs": [],
   "source": [
    "def fold_tree(tree):\n",
    "  if not tree.get(\"children\"):\n",
    "    return tree\n",
    "  for child in tree[\"children\"]:\n",
    "    child = fold_tree(child)\n",
    "  if len(tree[\"children\"])==1:\n",
    "    tree[\"name\"] = tree[\"name\"] + \" \" + tree[\"children\"][0][\"name\"]\n",
    "    tree[\"size\"] = tree.get(\"size\",0) + tree[\"children\"][0].get(\"size\",0)\n",
    "    tree[\"children\"] = tree[\"children\"][0].get(\"children\",None)\n",
    "  return tree\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:54:28.170066Z",
     "start_time": "2018-06-09T23:54:28.165066Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_tree = fold_tree(raw_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:54:28.401067Z",
     "start_time": "2018-06-09T23:54:28.396066Z"
    }
   },
   "outputs": [],
   "source": [
    "new_tree = raw_tree.copy()\n",
    "new_tree[\"raw_children\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:54:28.801068Z",
     "start_time": "2018-06-09T23:54:28.770064Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('tree.json', 'w') as outfile:\n",
    "    json.dump(new_tree, outfile, indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T23:54:29.167065Z",
     "start_time": "2018-06-09T23:54:29.150071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'children': None,\n",
       "  'name': 'are the hierarchical hidden markov model [ 3 ] and the abstract hidden markov model',\n",
       "  'size': 1},\n",
       " {'children': None,\n",
       "  'name': 'can be applied to categorize human behavior at various levels of abstraction',\n",
       "  'size': 1},\n",
       " {'name': 'exist', 'size': 1},\n",
       " {'children': None,\n",
       "  'name': 'used in different situations , depending on whether every sequential state is observable or not , and whether the system is to be adjusted on the basis of observations made :',\n",
       "  'size': 1}]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subitem = [item[\"children\"] for item in raw_tree[\"children\"] if item[\"name\"]==\"models\"] \n",
    "subitem[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T04:15:18.792324Z",
     "start_time": "2018-06-10T04:15:18.651324Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-177-fa5b38373027>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-177-fa5b38373027>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    r.extract_keywords_from_text(<text to process>)\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
